# MemOS Environment Variables Configuration
# Copy this file to .env and fill in your actual values

# ==============================================================================
# LLM Provider Configuration
# ==============================================================================

# OpenAI Configuration (Choose one of the following)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# Ollama Configuration (Alternative to OpenAI)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2

# ==============================================================================
# Memory Storage Configuration
# ==============================================================================

# Local storage paths
MEMOS_DATA_DIR=./data
MEMOS_CACHE_DIR=./cache
MEMOS_LOG_DIR=./logs

# ==============================================================================
# Optional External Services
# ==============================================================================

# Neo4j Configuration (for tree memory)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password

# Redis Configuration (for memory scheduler)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password

# Qdrant Configuration (for vector storage)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=your_qdrant_api_key

# ==============================================================================
# API Configuration
# ==============================================================================

# FastAPI server configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# ==============================================================================
# Development Configuration
# ==============================================================================

# Debug mode
DEBUG=false
LOG_LEVEL=INFO

# Test configuration
TEST_MODE=false
MOCK_LLM=false